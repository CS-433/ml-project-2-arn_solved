{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Read main dataset and annotation about cell type adn centriole existence \n",
    "df = pd.read_csv('./data/S7_table.csv')\n",
    "annotation = pd.read_csv('./data/annotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of existing centriol\n",
    "annotation = annotation.drop(columns = ['cell_status'])\n",
    "annotation['centriole'] = np.where(annotation['centriole'] == 'absent', 0, annotation['centriole'])\n",
    "annotation['centriole'] = np.where(annotation['centriole'] == 'present', 1, annotation['centriole'])\n",
    "\n",
    "# dictionary of centriole\n",
    "annotation_dictionary = annotation.set_index('cell_type').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete from main dataset undefferentiated cell type and adjusted.tmp equals 0.0  \n",
    "df.drop(df[df['adjusted.tpm.estimate'] == 0.0].index, inplace = True)\n",
    "df.drop(df[df[\"cell.bin\"].apply(lambda x: define_undefferentiated(x)) == True].index, inplace = True)\n",
    "\n",
    "# drop columns which will not be used\n",
    "df.drop('raw.tpm.estimate', inplace=True, axis=1)\n",
    "df.drop('bootstrap.median.tpm', inplace=True, axis=1)\n",
    "df.drop('ci.95p.lb', inplace=True, axis=1)\n",
    "df.drop('ci.80p.lb', inplace=True, axis=1)\n",
    "df.drop('ci.95p.ub', inplace=True, axis=1)\n",
    "df.drop('ci.80p.ub', inplace=True, axis=1)\n",
    "\n",
    "# add column with cell type and cell bin\n",
    "df['cell_type'] = df[\"cell.bin\"].apply(lambda x: split_cell_type(x, 1))\n",
    "df['cell_bin'] = df[\"cell.bin\"].apply(lambda x: split_cell_type(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataFrame for new data\n",
    "general_df = pd.DataFrame()\n",
    "keys = ['210_270', '270_330', '330_390', '390_450', '450_510', '510_580', '580_650', 'gt_650']\n",
    "\n",
    "for gene, group in df.groupby(['gene']):\n",
    "    general_df_cell = pd.DataFrame()\n",
    "    for cell_type, cell in group.groupby(['cell_type']):\n",
    "        dict_cell_tb = {}\n",
    "        for i in keys:\n",
    "            dict_cell_tb[i] = 0.0\n",
    "        # assing existiing estimate\n",
    "        for index in range(cell['cell_bin'].size):\n",
    "            value_tb_table = cell[\"cell_bin\"].values[index]\n",
    "            estimate = cell['adjusted.tpm.estimate'].values[index]\n",
    "            if cell['adjusted.tpm.estimate'].size == 1:\n",
    "                for i in keys:\n",
    "                    dict_cell_tb[i] = estimate\n",
    "                break\n",
    "            if value_tb_table in dict_cell_tb.keys():\n",
    "                dict_cell_tb[value_tb_table] = estimate\n",
    "            else: \n",
    "                for k in dict_cell_tb:\n",
    "                    k_split = k.split('_')\n",
    "                    tb_split = value_tb_table.split('_')\n",
    "                    if (k_split[0] == tb_split[0] or k_split[1] == tb_split[0] or k_split[0] == tb_split[1] or k_split[1] == tb_split[1]) > 0:\n",
    "                        if k_split[0] == tb_split[0]:\n",
    "                            dict_cell_tb[k] =  estimate\n",
    "                        if dict_cell_tb[k] == 0.0: \n",
    "                                dict_cell_tb[k] =  estimate\n",
    "\n",
    "        # fill zero value with nearest value in dictionary\n",
    "        for k in dict_cell_tb:\n",
    "            if dict_cell_tb[k] != 0.0:\n",
    "                value = dict_cell_tb[k]\n",
    "                dict_cell_tb = fill_zeros(k, value, 0, dict_cell_tb)    \n",
    "                    \n",
    "        for key in reversed(dict_cell_tb):\n",
    "            if dict_cell_tb[key] != 0.0:\n",
    "                value = dict_cell_tb[key]\n",
    "                dict_cell_tb = fill_zeros(key, value, 1, dict_cell_tb)  \n",
    "        \n",
    "        # add dataFrame of bins and bins for particular cell\n",
    "        df_cell = pd.DataFrame.from_dict([dict_cell_tb])\n",
    "        df_cell[\"cell_type\"] = cell_type\n",
    "        df_cell['centriole'] = annotation_dictionary[cell_type]\n",
    "        df_cell['gene'] =  gene\n",
    "        if general_df_cell.empty:\n",
    "            general_df_cell = df_cell\n",
    "        else:\n",
    "            general_df_cell = pd.concat([general_df_cell, df_cell], axis=0)\n",
    "    # add dataFrame of cell type and bins for particular gene\n",
    "    if general_df.empty:\n",
    "        general_df = general_df_cell\n",
    "    else:\n",
    "        general_df = pd.concat([general_df, general_df_cell], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change order of column\n",
    "data = general_df[[\"gene\",\"cell_type\",\"210_270\",\"270_330\", \"330_390\", \"390_450\", \"450_510\", \"510_580\", \"580_650\", \"gt_650\", \"centriole\"]]\n",
    "\n",
    "# save resulting dataset for future calculation \n",
    "data.to_csv('./data/data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb9837ce44412c5b8156e4a2164b06139617fec1a99283424b39abb5e56630ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
